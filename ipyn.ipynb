{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb\n\n# Load the data\ntrain_data = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ntest_data = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\n\n# Separate features and target\nX = train_data.drop(['Id', 'SalePrice'], axis=1)\ny = train_data['SalePrice']\ntest_features = test_data.drop('Id', axis=1)\n\n# Identify numeric and categorical columns\nnumeric_features = X.select_dtypes(include=['int64', 'float64']).columns\ncategorical_features = X.select_dtypes(include=['object']).columns\n\n# Create preprocessing pipelines\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Combine preprocessing steps\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)\n    ])\n\n# Create a preprocessing and modeling pipeline\nrf_model = Pipeline(steps=[('preprocessor', preprocessor),\n                           ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))])\n\nxgb_model = Pipeline(steps=[('preprocessor', preprocessor),\n                            ('regressor', xgb.XGBRegressor(n_estimators=100, random_state=42))])\n\nlgb_model = Pipeline(steps=[('preprocessor', preprocessor),\n                            ('regressor', lgb.LGBMRegressor(n_estimators=100, random_state=42))])\n\n# Split the data\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train and evaluate models\nmodels = [rf_model, xgb_model, lgb_model]\nmodel_names = ['Random Forest', 'XGBoost', 'LightGBM']\n\nfor model, name in zip(models, model_names):\n    model.fit(X_train, np.log1p(y_train))\n    val_predictions = model.predict(X_val)\n    val_rmse = np.sqrt(mean_squared_error(np.log1p(y_val), val_predictions))\n    print(f\"{name} Validation RMSE: {val_rmse}\")\n\n# Choose the best model (for this example, let's assume XGBoost performed best)\nbest_model = xgb_model\n\n# Retrain on full training data\nbest_model.fit(X, np.log1p(y))\n\n# Make predictions on test data\ntest_predictions = np.expm1(best_model.predict(test_features))\n\n# Create submission file\nsubmission = pd.DataFrame({\n    'Id': test_data['Id'],\n    'SalePrice': test_predictions\n})\nsubmission.to_csv('submission.csv', index=False)\n\nprint(\"Submission file created successfully!\")\n\n# Feature importance (for XGBoost)\nfeature_importance = best_model.named_steps['regressor'].feature_importances_\nfeature_names = best_model.named_steps['preprocessor'].get_feature_names_out()\n\nimportance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importance})\nimportance_df = importance_df.sort_values('importance', ascending=False).head(20)\n\nprint(\"\\nTop 20 Most Important Features:\")\nprint(importance_df)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T12:15:37.591448Z","iopub.execute_input":"2024-09-10T12:15:37.591917Z","iopub.status.idle":"2024-09-10T12:15:50.596957Z","shell.execute_reply.started":"2024-09-10T12:15:37.591877Z","shell.execute_reply":"2024-09-10T12:15:50.595702Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
